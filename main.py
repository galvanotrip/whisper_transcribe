import os
import math
import tempfile
import ffmpeg
from faster_whisper import WhisperModel

CHUNK_SECONDS = 300  # 5 –º–∏–Ω—É—Ç

def get_duration(file_path):
    probe = ffmpeg.probe(file_path)
    return float(probe["format"]["duration"])

def split_audio(input_file, chunk_length):
    temp_dir = tempfile.mkdtemp()
    duration = get_duration(input_file)
    chunks = []

    for i in range(0, math.ceil(duration / chunk_length)):
        out_path = os.path.join(temp_dir, f"chunk_{i}.wav")
        ffmpeg.input(input_file, ss=i * chunk_length, t=chunk_length).output(
            out_path, ac=1, ar='16000'
        ).run(overwrite_output=True, quiet=True)
        chunks.append(out_path)

    return chunks

def transcribe_chunk(model, audio_path):
    segments, _ = model.transcribe(audio_path)
    return "\n".join([seg.text for seg in segments])

def transcribe_long_audio(file_path, output_txt="transcription.txt"):
    print("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
    model = WhisperModel("base", compute_type="int8")  # –º–æ–∂–µ—à—å –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å "small" –∏–ª–∏ "medium"

    print("‚úÇÔ∏è –†–µ–∂–µ–º –Ω–∞ —á–∞—Å—Ç–∏...")
    chunks = split_audio(file_path, CHUNK_SECONDS)

    final_text = ""
    for idx, chunk in enumerate(chunks):
        print(f"üéß –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–∏ {idx + 1}/{len(chunks)}...")
        text = transcribe_chunk(model, chunk)
        final_text += text + "\n"

    with open(output_txt, "w", encoding="utf-8") as f:
        f.write(final_text)

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ—Ö—Ä–∞–Ω–∏–ª –≤: {output_txt}")

if __name__ == "__main__":
    input_file = "./test.mp4"  # –∑–∞–º–µ–Ω–∏ –Ω–∞ —Å–≤–æ–π –ø—É—Ç—å
    transcribe_long_audio(input_file)